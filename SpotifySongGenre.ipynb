{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spotify_dataset.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Data loaded and pre-processed. Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Matrix of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select numerical columns for correlation matrix\n",
    "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = numerical_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding Optimal Number of Clusters (Elbow Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numerical_df)\n",
    "\n",
    "# Find the optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(scaled_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Means Clustering and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform K-Means clustering\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Reduce dimensionality using PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "# Create a DataFrame with the principal components and cluster labels\n",
    "pca_df = pd.DataFrame(data = principal_components, columns = ['principal component 1', 'principal component 2'])\n",
    "pca_df['cluster'] = df['cluster']\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='principal component 1', y='principal component 2', hue='cluster', data=pca_df, palette='viridis')\n",
    "plt.title('Clusters of Songs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters by playlist genre\n",
    "print(\"Cluster distribution by playlist genre:\")\n",
    "print(df.groupby(['cluster', 'playlist_genre']).size().unstack(fill_value=0))\n",
    "\n",
    "# Analyze clusters by playlist name (top 5 per cluster)\n",
    "print(\"\nTop 5 playlist names per cluster:\")\n",
    "for i in range(k):\n",
    "    print(f\"\nCluster {i}:\")\n",
    "    playlist_counts = df[df['cluster'] == i].groupby('playlist_name').size().nlargest(5)\n",
    "    print(playlist_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(track_name, df):\n",
    "    \"\"\"Recommends songs from the same cluster as the input song.\"\"\"\n",
    "    try:\n",
    "        cluster = df[df['track_name'] == track_name]['cluster'].iloc[0]\n",
    "        recommended_songs = df[df['cluster'] == cluster].sample(5)['track_name']\n",
    "        return recommended_songs\n",
    "    except IndexError:\n",
    "        return \"Song not found.\"\n",
    "\n",
    "# Example usage:\n",
    "print(\"Recommendations for 'bad guy':\")\n",
    "print(recommend_songs('bad guy', df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
